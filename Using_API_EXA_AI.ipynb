{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreiarossi/EXA_API/blob/main/Using_API_EXA_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install exa_py"
      ],
      "metadata": {
        "id": "LGDBUclTvtFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "**1st EXEMPLE**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "b_s78-g-jrkC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXod5c0cvdzL"
      },
      "outputs": [],
      "source": [
        "from time import timezone\n",
        "from exa_py import Exa\n",
        "\n",
        "# Exa API_KEY, get on website\n",
        "#exa = Exa(\"YOUR_API_EXA\")\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('Exa_API')\n",
        "exa = Exa(api_key)\n",
        "\n",
        "# Search\n",
        "results = exa.search(\n",
        "    \"Show me the lasts paper related to neurobiomimetic processing published in 2025\",\n",
        "    category=\"papers\" #query category (you can add/configure more: see exa.ai)\n",
        ")\n",
        "# Shows search results\n",
        "for result in results.results:\n",
        "    print(\"Título:\", result.title)\n",
        "    print(\"Link:\", result.url)\n",
        "    print(\"ID:\", result.id)\n",
        "    print(\"Score:\", result.score)\n",
        "    print(\"Data de Publicação:\", result.published_date)\n",
        "    print(\"Autor:\", result.author)\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**2nd EXEMPLE**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "reyAqHwUjjvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from exa_py import Exa\n",
        "\n",
        "# Exa API_KEY, get on website\n",
        "#exa = Exa(\"YOUR_API_EXA\")\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('Exa_API')\n",
        "exa = Exa(api_key)\n",
        "# Search\n",
        "result = exa.search_and_contents(\n",
        "    \"Show me the lasts DeepSeek publications\",\n",
        "    type=\"neural\",\n",
        "    use_autoprompt=True,\n",
        "    num_results=20,\n",
        "    summary={\n",
        "        \"query\": \"What does this paper cover?\"\n",
        "    },\n",
        "    category=\"research paper\",\n",
        "    exclude_domains=[\"en.wikipedia.org\"],\n",
        "    start_published_date=\"2024-01-01\"\n",
        ")\n",
        "\n",
        "# Shows search results\n",
        "for paper in result.results:\n",
        "    print(\"Title:\", paper.title)\n",
        "    print(\"URL:\", paper.url)\n",
        "\n",
        "    # Access publish data attributes\n",
        "    print(\"Publication Date:\", paper.published_date)  # Try with 'published_date' or another one\n",
        "\n",
        "    print(\"Author:\", paper.author)\n",
        "    print(\"Summary:\", paper.summary)\n",
        "    print(\"\\n\" + \"-\"*80 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "LZ_Fobw9zWOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25eb87c8-5380-4a7c-c400-9affe0fe042a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: LLM & HPC:Benchmarking DeepSeek's Performance in High-Performance Computing Tasks\n",
            "URL: https://www.arxiv.org/abs/2504.03665\n",
            "Publication Date: 2025-03-15T00:00:00.000Z\n",
            "Author: [Submitted on 15 Mar 2025]\n",
            "Summary: This paper benchmarks the performance of the DeepSeek large language model (LLM) in generating High-Performance Computing (HPC) benchmark codes.  It compares DeepSeek's code generation capabilities in C++, Fortran, Julia, and Python against GPT-4 across several HPC tasks (conjugate gradient solver, parallel heat equation, parallel matrix multiplication, DGEMM, and STREAM triad). The evaluation considers code correctness, performance, and scalability, revealing that while DeepSeek produces functional code, it underperforms GPT-4 in scalability and execution efficiency.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: NutriGen: Personalized Meal Plan Generator Leveraging Large Language Models to Enhance Dietary and Nutritional Adherence\n",
            "URL: https://arxiv.org/abs/2502.20601\n",
            "Publication Date: 2025-02-28T00:00:00.000Z\n",
            "Author: [Submitted on 28 Feb 2025]\n",
            "Summary: This paper introduces NutriGen, a framework using large language models (LLMs) to generate personalized meal plans.  It addresses limitations of existing dietary recommendation systems by creating plans that consider user preferences, dietary restrictions, and food availability.  The system leverages prompt engineering and a personalized nutrition database (including data like the USDA nutrition database) for accuracy.  Evaluation shows Llama 3.1 8B and GPT-3.5 Turbo achieved the lowest error rates in generating meal plans aligning with specified caloric targets.  The paper highlights LLMs' potential for creating accurate, user-friendly, and scalable meal planning solutions.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: User Intent to Use DeekSeep for Healthcare Purposes and their Trust in the Large Language Model: Multinational Survey Study\n",
            "URL: https://arxiv.org/abs/2502.17487\n",
            "Publication Date: 2025-02-18T00:00:00.000Z\n",
            "Author: [Submitted on 18 Feb 2025]\n",
            "Summary: This paper investigates user intent to utilize DeekSeep, an LLM-based healthcare platform.  A multinational survey (556 participants from India, the UK, and the US) explored how ease of use, perceived usefulness, trust, and risk perception influence adoption.  The study used structural equation modeling to reveal that trust is a key mediator: ease of use indirectly impacts usage intentions through trust, while perceived usefulness directly impacts both trust and adoption.  Risk perception negatively affects usage intent.  Non-linear relationships were found for ease of use and risk perception.  The findings highlight the importance of trust-building strategies, user-centric design, and risk mitigation for successful LLM implementation in healthcare.  Future research should explore longitudinal effects and cultural variations.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: Token-Hungry, Yet Precise: DeepSeek R1 Highlights the Need for Multi-Step Reasoning Over Speed in MATH\n",
            "URL: https://arxiv.org/abs/2501.18576\n",
            "Publication Date: 2025-01-30T00:00:00.000Z\n",
            "Author: [Submitted on 30 Jan 2025]\n",
            "Summary: This paper evaluates the DeepSeek R1 language model's performance on 30 challenging mathematical problems from the MATH dataset, previously unsolvable by other models within time constraints.  Unlike previous research, this study removes time limits to assess DeepSeek R1's accuracy using its token-based reasoning approach.  Comparing DeepSeek R1 to four other models across various temperature settings, the results show DeepSeek R1 achieves higher accuracy but generates significantly more tokens.  The study concludes that there's a trade-off between accuracy and efficiency in using LLMs for mathematical problem-solving, highlighting the importance of considering task-specific needs when choosing a model.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: A Review of DeepSeek Models' Key Innovative Techniques\n",
            "URL: https://arxiv.org/abs/2503.11486\n",
            "Publication Date: 2025-03-14T00:00:00.000Z\n",
            "Author: [Submitted on 14 Mar 2025]\n",
            "Summary: This paper reviews the key innovative techniques behind DeepSeek-V3 and DeepSeek-R1, two open-source Large Language Models (LLMs).  These models achieve performance comparable to closed-source LLMs while being significantly cheaper to train.  The review covers architectural refinements, including Multi-Head Latent Attention, Mixture of Experts, and Multi-Token Prediction.  It also discusses the co-design of algorithms, frameworks, and hardware; the Group Relative Policy Optimization algorithm; post-training with pure reinforcement learning; and iterative training alternating between supervised fine-tuning and reinforcement learning.  Finally, the paper identifies open research questions in the field.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: DeepSee: Multidimensional Visualizations of Seabed Ecosystems\n",
            "URL: https://arxiv.org/abs/2403.04761\n",
            "Publication Date: 2024-03-07T00:00:00.000Z\n",
            "Author: Coscia; Adam; Sapers; Haley M; Deutsch; Noah; Khurana; Malika; Magyar; John S; Parra; Sergio A; Utter; Daniel R; Wipfler; Rebecca L; Caress; David W; Martin; Eric J; Paduan; Jennifer B; Hendrie; Maggie; Lombeyda; Santiago; Mushkin; Hillary; Endert; Alex; Davidoff; Scott; Orphan; Victoria J\n",
            "Summary: This paper introduces DeepSee, an interactive data workspace designed to visualize biogeochemical and microbial processes in deep-sea ecosystems.  It addresses the challenges of limited seabed sampling by allowing researchers to visualize 2D and 3D interpolations of data, overlaid on seafloor maps, alongside sampling history.  The authors conducted a user-centered design study showing DeepSee increased scientific return from limited samples, fostered new research workflows, reduced data-sharing costs, and improved team collaboration.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: Bridging Technology and Humanities: Evaluating the Impact of Large Language Models on Social Sciences Research with DeepSeek-R1\n",
            "URL: https://arxiv.org/abs/2503.16304\n",
            "Publication Date: 2025-03-20T00:00:00.000Z\n",
            "Author: [Submitted on 20 Mar 2025]\n",
            "Summary: This paper evaluates the large language model (LLM) DeepSeek-R1's impact on social sciences research.  The authors analyze DeepSeek-R1's performance across seven applications: low-resource language translation, educational Q&A, student writing improvement, logical reasoning, educational measurement, public health policy analysis, and art analysis.  They compare DeepSeek-R1 to o1-preview, finding DeepSeek-R1 superior in providing detailed explanations and reasoning processes, making it suitable for beginners. The paper concludes that LLMs like DeepSeek-R1 have broad application potential in social sciences, enhancing text analysis efficiency and language communication.  A note indicates text overlap with a previous paper (arXiv:2409.18486).\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: DeepSeek-R1 Thoughtology: Let's <think> about LLM Reasoning\n",
            "URL: https://arxiv.org/abs/2504.07128\n",
            "Publication Date: 2025-04-02T00:00:00.000Z\n",
            "Author: [Submitted on 2 Apr 2025]\n",
            "Summary: This paper analyzes DeepSeek-R1, a large language model (LLM) that uses multi-step reasoning chains to solve complex problems.  The authors investigate several aspects of DeepSeek-R1's reasoning process, including the impact of reasoning chain length on performance (finding an optimal \"sweet spot\"), the model's tendency to get stuck on previous problem formulations, and its safety vulnerabilities compared to non-reasoning LLMs.  The paper also explores the broader implications of DeepSeek-R1's reasoning capabilities for understanding LLM behavior and its relationship to human-like cognitive processes.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: An evaluation of DeepSeek Models in Biomedical Natural Language Processing\n",
            "URL: https://arxiv.org/abs/2503.00624\n",
            "Publication Date: 2025-03-01T00:00:00.000Z\n",
            "Author: [Submitted on 1 Mar 2025]\n",
            "Summary: This paper evaluates the performance of DeepSeek models (Distilled-DeepSeek-R1 and DeepSeek-LLMs) on four biomedical natural language processing (NLP) tasks: named entity recognition, relation extraction, event extraction, and text classification.  Using 12 datasets and comparing against other state-of-the-art LLMs (Llama3-8B, Qwen2.5-7B, Mistral-7B, Phi-4-14B, Gemma-2-9B), the authors find that DeepSeek models are competitive in named entity recognition and text classification but show limitations in event and relation extraction due to precision-recall trade-offs.  The paper offers task-specific model recommendations and suggests future research directions to improve DeepSeek models' performance in biomedical NLP.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: Evaluating the Performance of the DeepSeek Model in Confidential Computing Environment\n",
            "URL: https://arxiv.org/abs/2502.11347\n",
            "Publication Date: 2025-02-17T00:00:00.000Z\n",
            "Author: [Submitted on 17 Feb 2025]\n",
            "Summary: This paper evaluates the performance of the DeepSeek large language model (LLM) within Intel Trust Domain Extensions (TDX) confidential computing environments.  The authors benchmark DeepSeek's performance using CPU-only, CPU-GPU hybrid, and TEE-based implementations.  They find that for smaller DeepSeek models, the TDX implementation is faster than the CPU-only version, demonstrating the potential for secure and efficient LLM deployment on resource-constrained systems.  The study also reveals an average GPU-to-CPU performance ratio of 12 across different model sizes and offers insights into optimizing CPU-GPU confidential computing for scalable and secure AI.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: Can LLMs Assist Computer Education? an Empirical Case Study of DeepSeek\n",
            "URL: https://arxiv.org/abs/2504.00421\n",
            "Publication Date: 2025-04-01T00:00:00.000Z\n",
            "Author: [Submitted on 1 Apr 2025]\n",
            "Summary: This paper presents an empirical case study investigating the use of Large Language Models (LLMs), specifically DeepSeek, to assist in computer science education.  The study's focus is on evaluating the effectiveness of LLMs in this context.  Further details on the methodology and findings are not provided in the abstract.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: Unveiling the Mathematical Reasoning in DeepSeek Models: A Comparative Study of Large Language Models\n",
            "URL: https://arxiv.org/abs/2503.10573\n",
            "Publication Date: 2025-03-13T00:00:00.000Z\n",
            "Author: [Submitted on 13 Mar 2025]\n",
            "Summary: This paper conducts a comparative study of large language models (LLMs), focusing on their mathematical reasoning capabilities.  It specifically evaluates two DeepSeek models against five other prominent LLMs across three benchmark datasets.  Key findings include DeepSeek-R1's superior performance on two datasets, the underperformance of distilled LLMs, and Gemini 2.0 Flash's speed advantage.  The research analyzes the influence of architecture, training, and optimization on mathematical reasoning and identifies areas for future improvement in LLM-driven mathematical reasoning.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: DeepSeek reshaping healthcare in China's tertiary hospitals\n",
            "URL: https://arxiv.org/abs/2502.16732\n",
            "Publication Date: 2025-02-23T00:00:00.000Z\n",
            "Author: [Submitted on 23 Feb 2025]\n",
            "Summary: This paper discusses DeepSeek, an AI system deployed in China's tertiary hospitals since January 2025.  It enhances diagnostic accuracy, streamlines workflows, and improves patient management through AI-powered pathology, imaging analysis, and clinical decision support.  The authors also address the regulatory and ethical challenges of widespread AI adoption in healthcare, highlighting concerns about accountability and automation bias, and advocating for transparent regulatory structures to ensure responsible AI implementation.  The future of AI in healthcare, according to the paper, hinges on responsible innovation and collaborative efforts to create equitable and effective AI-driven medical services.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: Output Length Effect on DeepSeek-R1's Safety in Forced Thinking\n",
            "URL: https://arxiv.org/abs/2503.01923\n",
            "Publication Date: 2025-03-02T00:00:00.000Z\n",
            "Author: [Submitted on 2 Mar 2025]\n",
            "Summary: This paper investigates the effect of output length on the safety of the DeepSeek-R1 large language model (LLM), especially in adversarial \"Forced Thinking\" scenarios.  The researchers found that while longer outputs can sometimes improve safety through self-correction,  longer generations can also be exploited by certain attack types.  Their findings suggest that dynamically controlling output length is crucial to balance reasoning effectiveness and security.  The paper proposes using reinforcement learning and adaptive token length regulation to enhance LLM safety.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: Safety Evaluation of DeepSeek Models in Chinese Contexts\n",
            "URL: https://arxiv.org/abs/2502.11137\n",
            "Publication Date: 2025-02-16T00:00:00.000Z\n",
            "Author: [Submitted on 16 Feb 2025]\n",
            "Summary: This paper evaluates the safety of DeepSeek-R1 and DeepSeek-V3, large language models, specifically within Chinese language contexts.  Previous research highlighted significant safety vulnerabilities in DeepSeek models, particularly a 100% attack success rate with harmful prompts in DeepSeek-R1.  This study addresses the lack of Chinese-language safety assessments by introducing CHiSafetyBench, a new benchmark.  The paper then uses this benchmark to quantify the safety deficiencies of DeepSeek-R1 and DeepSeek-V3 in Chinese, providing insights for future model improvements.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: ChatGPT vs. DeepSeek: A Comparative Study on AI-Based Code Generation\n",
            "URL: https://arxiv.org/abs/2502.18467\n",
            "Publication Date: 2025-01-30T00:00:00.000Z\n",
            "Author: [Submitted on 30 Jan 2025]\n",
            "Summary: This paper compares the performance of ChatGPT (version o1) and DeepSeek (version R1) in generating Python code for online judge coding challenges.  The comparison focuses on code correctness (using online judge verdicts), code quality (using Pylint/Flake8), and efficiency (execution time and memory usage).  DeepSeek showed higher correctness, especially on algorithmic tasks, often producing correct code on the first attempt.  ChatGPT sometimes needed multiple attempts.  However, ChatGPT used slightly less memory and execution time and produced shorter code.  The conclusion highlights DeepSeek's superior correctness for algorithmic problems, while both models exhibited similar efficiency.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: Leveraging Large Language Models for Cost-Effective, Multilingual Depression Detection and Severity Assessment\n",
            "URL: https://arxiv.org/abs/2504.04891\n",
            "Publication Date: 2025-04-07T00:00:00.000Z\n",
            "Author: [Submitted on 7 Apr 2025]\n",
            "Summary: This paper evaluates four large language models (LLMs) for detecting and assessing the severity of depression using clinical interview data.  The study found DeepSeek V3 to be the most cost-effective and reliable model, performing well in both zero-shot and few-shot learning scenarios. While DeepSeek V3 demonstrated strong potential for depression detection in complex scenarios, the results showed lower accuracy in assessing depression severity, particularly for mild cases.  The authors highlight the need for further improvements in severity assessment and bias mitigation for enhanced clinical reliability.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: From ChatGPT to DeepSeek AI: A Comprehensive Analysis of Evolution, Deviation, and Future Implications in AI-Language Models\n",
            "URL: https://arxiv.org/abs/2504.03219\n",
            "Publication Date: 2025-04-04T00:00:00.000Z\n",
            "Author: [Submitted on 4 Apr 2025]\n",
            "Summary: This paper analyzes the evolution of AI language models, comparing ChatGPT and the newer DeepSeek AI.  It details their architectural differences, performance improvements in DeepSeek AI, and the ethical considerations involved.  A case study using multiple-choice questions across various domains assessed the strengths and weaknesses of both models. The authors offer insights into the future of AI language models and potential industry transformations.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: Comprehensive Analysis of Transparency and Accessibility of ChatGPT, DeepSeek, And other SoTA Large Language Models\n",
            "URL: https://arxiv.org/abs/2502.18505\n",
            "Publication Date: 2025-02-21T00:00:00.000Z\n",
            "Author: [Submitted on 21 Feb 2025]\n",
            "Summary: This paper analyzes the transparency and accessibility of leading Large Language Models (LLMs), including ChatGPT and DeepSeek, over the past five years.  It examines whether these models meet transparency standards, considering both open-source and open-weight aspects.  The authors find that even models labeled \"open-source\" often lack full transparency, failing to disclose training data, code, key metrics, and carbon emissions.  This is the first study to systematically assess over 100 LLMs using this dual-lens approach, highlighting the need for more responsible and sustainable AI practices.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Title: Paper page - DeepSeek-V3 Technical Report\n",
            "URL: https://huggingface.co/papers/2412.19437\n",
            "Publication Date: 2025-01-09T00:00:00.000Z\n",
            "Author: DeepSeek-AI ,\n",
            "Summary: This paper introduces DeepSeek-V3, a 671B parameter Mixture-of-Experts (MoE) language model.  Key innovations include using Multi-head Latent Attention (MLA) and the DeepSeekMoE architecture (previously validated in DeepSeek-V2), an auxiliary-loss-free load balancing strategy, and a multi-token prediction training objective.  Trained on 14.8 trillion tokens, DeepSeek-V3 achieves performance comparable to leading closed-source models while requiring only 2.788M H800 GPU hours for training, demonstrating remarkable stability.  Model checkpoints are available on GitHub.\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}